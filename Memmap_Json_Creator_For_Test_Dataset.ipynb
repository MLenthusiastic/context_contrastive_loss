{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Memmap_Json_Creator_For_Test_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxD2HXgbcRVbDqnuRH7p/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLenthusiastic/context_contrastive_loss/blob/master/Memmap_Json_Creator_For_Test_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yFq4e78q61r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZxM8dIygB8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic_light', 'fire_hydrant', 'N/A', 'stop_sign',\n",
        "    'parking_meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports_ball',\n",
        "    'kite', 'baseball_bat', 'baseball_glove', 'skateboard', 'surfboard', 'tennis_racket',\n",
        "    'bottle', 'N/A', 'wine_glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot_dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted_plant', 'bed', 'N/A', 'dining_table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell_phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy_bear', 'hair_drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "def get_prediction(img_path, threshold):\n",
        "    img = Image.open(img_path)\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    img = transform(img)\n",
        "    pred = model([img])\n",
        "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
        "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
        "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
        "    pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]\n",
        "    pred_boxes = pred_boxes[:pred_t + 1]\n",
        "    pred_class = pred_class[:pred_t + 1]\n",
        "    return pred_boxes, pred_class\n",
        "\n",
        "def object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3):\n",
        "  boxes, pred_cls = get_prediction(img_path, threshold)\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  for i in range(len(boxes)):\n",
        "    cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th)\n",
        "    cv2.putText(img,pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th)\n",
        "  plt.figure(figsize=(20,30))\n",
        "  plt.imshow(img)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "#object_detection_api('./bird.jpg', threshold=0.5)\n",
        "#boxes, pred_cls = get_prediction('./2.jpg', threshold=0.6)\n",
        "#print(pred_cls)\n",
        "#print(boxes)\n",
        "\n",
        "need_classes = ['person', 'tennis_racket','sports_ball','horse','surfboard','skateboard',\n",
        "                'sheep','motorcycle','backpack','kite','sports_ball','bird','dog','bicycle',\n",
        "                'handbag']\n",
        "\n",
        "folder_path = './drive/My Drive/Datasets/Test_Davis/'\n",
        "included_extensions = ['jpg','jpeg', 'bmp', 'png', 'gif']\n",
        "image_names = [fn for fn in os.listdir(folder_path)\n",
        "              if any(fn.endswith(ext) for ext in included_extensions)]\n",
        "\n",
        "class_label_dict = {}\n",
        "img_objects = {}\n",
        "frame_context = {}\n",
        "object_idx = 0\n",
        "\n",
        "img = cv2.imread(os.path.join(folder_path,image_names[0]))\n",
        "frame_height, frame_width, channels = img.shape\n",
        "\n",
        "path = './drive/My Drive/'\n",
        "memmap_path = path + 'test_davis.mmap'\n",
        "mem = np.memmap(memmap_path, dtype='uint8', mode='w+', \n",
        "                shape=(len(image_names)*5, channels, frame_width, frame_height))\n",
        "\n",
        "\n",
        "for image_name in image_names:\n",
        "    print(image_name)\n",
        "    boxes, pred_cls = get_prediction(folder_path+image_name, threshold=0.6)\n",
        "    np_boxes = np.array(boxes)\n",
        "    np_classes = np.array(pred_cls)\n",
        "\n",
        "    image_frame = cv2.imread(folder_path + image_name)\n",
        "    images_in_frame = []\n",
        "\n",
        "    for class_, box_ in zip(np_classes, np_boxes):\n",
        "      if class_ in need_classes:\n",
        "        object = {}\n",
        "        object[\"object_idx\"] = object_idx\n",
        "        frame_idx = int(image_name.split('.')[0])\n",
        "        object[\"frame_idx\"] = frame_idx\n",
        "\n",
        "        # adding object to relevant frame\n",
        "        images_in_frame.append(object_idx)\n",
        "        \n",
        "        x = int(box_[0][0])\n",
        "        y = int(box_[0][1])\n",
        "        width = int(box_[1][0] - box_[0][0])\n",
        "        height = int(box_[1][1] - box_[0][1])\n",
        "\n",
        "        #storing in json\n",
        "        object[\"x\"] = x \n",
        "        object[\"y\"] = y\n",
        "        object[\"width\"] = width\n",
        "        object[\"height\"] = height\n",
        "        object[\"class\"] = class_\n",
        "        img_object = []\n",
        "        img_object.append(object)\n",
        "\n",
        "        img_objects[object_idx] = object\n",
        "        \n",
        "        #creating memmaps for each deteced objects\n",
        "        crop_img = image_frame[y:y + height, x:x + width]\n",
        "        crop_img_transposed = np.transpose(crop_img, (2, 1, 0))\n",
        "\n",
        "        im_padded = np.zeros([channels,frame_width,frame_height],dtype=crop_img_transposed.dtype)\n",
        "        im_padded[:, 0:crop_img_transposed.shape[1], 0:crop_img_transposed.shape[2]] = crop_img_transposed\n",
        "        mem[object_idx][:] = im_padded[:]\n",
        "\n",
        "        object_idx += 1\n",
        "\n",
        "        #show padded crop images\n",
        "        #retranspose = im_padded.transpose(2,1,0).reshape(frame_height,frame_width,channels)\n",
        "        #plt.imshow(cv2.cvtColor(retranspose, cv2.COLOR_BGR2RGB))\n",
        "        #plt.show()\n",
        "\n",
        "        if class_ in class_label_dict:\n",
        "          ex_list = []\n",
        "          ex_list.extend(class_label_dict.get(class_))\n",
        "          ex_list.extend(img_object)\n",
        "          class_label_dict[class_] = ex_list\n",
        "        else:\n",
        "          class_label_dict[class_] = img_object\n",
        "\n",
        "    frame_context[frame_idx] = images_in_frame\n",
        "\n",
        "mem = mem[0:object_idx,:,:,:]   \n",
        "\n",
        "all_images = {}\n",
        "all_images[\"shape\"] = (object_idx, channels, frame_width, frame_height)\n",
        "all_images[\"classes\"] = class_label_dict\n",
        "all_images[\"contexts\"] = frame_context\n",
        "all_images[\"objects\"] = img_objects\n",
        "\n",
        "\n",
        "json_path = path + 'test_davis.json'\n",
        "with open(json_path, 'w') as outfile:\n",
        "    json.dump(all_images, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}